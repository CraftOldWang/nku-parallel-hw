#include "guessing_cuda.h"
#include "PCFG.h"


#define CUDA_CHECK(call) \
    do { \
        cudaError_t err__ = (call); \
        if (err__ != cudaSuccess) { \
            fprintf(stderr, "\033[1;31m[CUDA ERROR]\033[0m %s:%d: %s (%d)\n", \
                __FILE__, __LINE__, cudaGetErrorString(err__), err__); \
            exit(EXIT_FAILURE); \
        } \
    } while (0)

// å®‰å…¨çš„CUDAé”™è¯¯æ£€æŸ¥ï¼ˆç”¨äºå›è°ƒå‡½æ•°ï¼‰
#define CUDA_CHECK_CALLBACK(call, cleanup_action) \
    do { \
        cudaError_t err__ = (call); \
        if (err__ != cudaSuccess) { \
            std::cerr << "CUDA error in callback: " << cudaGetErrorString(err__) << std::endl; \
            cleanup_action; \
            return; \
        } \
    } while (0)

AsyncGpuPipeline::AsyncTaskData::AsyncTaskData(TaskManager&& tm)
    : task_manager(std::move(tm)), gpu_buffer(nullptr) {
    // åˆ›å»ºCUDA streamså’Œevents
    cudaStreamCreate(&compute_stream);

    // åˆå§‹åŒ–æŒ‡é’ˆ
    temp_prefixs = nullptr;
    d_seg_types = nullptr;
    d_seg_ids = nullptr;
    d_seg_lens = nullptr;
    d_prefix_offsets = nullptr;
    d_prefix_lens = nullptr;
    d_seg_value_counts = nullptr;
    d_cumulative_guess_offsets = nullptr;
    d_output_offsets = nullptr;
    d_tasks = nullptr;
    d_guess_buffer = nullptr;
    h_prefix_offsets = nullptr;
    result_len = 0;
}

AsyncGpuPipeline::AsyncTaskData::~AsyncTaskData(){
            // æ¸…ç†CUDAèµ„æº
            if (compute_stream) cudaStreamDestroy(compute_stream);
}



void sync_gpu_task(AsyncGpuTask* task_data, PriorityQueue& q) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ¯ sync_gpu_task: Starting synchronous GPU task\n");
#endif

    try {
        
        // åˆ›å»ºä¸´æ—¶æ•°æ®ç»“æ„
        AsyncGpuPipeline::AsyncTaskData data(std::move(task_data->task_manager));
        
        // é˜¶æ®µ1: å‡†å¤‡GPUæ•°æ®
        prepare_gpu_data_stage(data);

        
        // é˜¶æ®µ2: å¯åŠ¨GPU kernel
        launch_kernel_stage(data);
        
        // ğŸ”¥ é˜¶æ®µ3: åŒæ­¥ç­‰å¾…GPUå®Œæˆ
        cudaError_t sync_err = cudaStreamSynchronize(data.compute_stream);
        if (sync_err != cudaSuccess) {
            throw std::runtime_error("GPU kernel execution failed: " + std::string(cudaGetErrorString(sync_err)));
        }
        
        // é˜¶æ®µ4: åŒæ­¥æ‹·è´ç»“æœå›CPU
        CUDA_CHECK(cudaMemcpy(data.gpu_buffer, data.d_guess_buffer, 
                             data.result_len * sizeof(char), cudaMemcpyDeviceToHost));
        
        // é˜¶æ®µ5: CPUå¤„ç†
        process_strings_stage(data);
        
        // é˜¶æ®µ6: åˆå¹¶ç»“æœåˆ°å…¨å±€é˜Ÿåˆ—
        merge_results_stage(data);
        
        // é˜¶æ®µ7: åŒæ­¥æ¸…ç†æ‰€æœ‰èµ„æº
        synchronous_cleanup(data);
        
#ifdef DEBUG
        printf("[DEBUG] âœ… sync_gpu_task: GPU task completed successfully\n");
#endif

    } catch (const std::exception& e) {
        std::cerr << "Sync GPU task failed: " << e.what() << std::endl;
        // å¼‚å¸¸ä¼šåœ¨ææ„å‡½æ•°ä¸­æ¸…ç†èµ„æº
    }
    
    delete task_data;

#ifdef DEBUG
    printf("[DEBUG] ğŸ—‘ï¸ sync_gpu_task: Task data deleted\n");
#endif
}


void AsyncGpuPipeline::launch_async_pipeline(TaskManager tm, PriorityQueue& q) {

    auto* async_data = new AsyncTaskData(std::move(tm));

    try {
        // é˜¶æ®µ1: å‡†å¤‡æ•°æ®ï¼ˆåŒæ­¥ï¼Œä½†å¯ä»¥ä¼˜åŒ–ï¼‰
        prepare_gpu_data_stage(*async_data);

        // é˜¶æ®µ2: å¼‚æ­¥å¯åŠ¨GPU kernel
        launch_kernel_stage(*async_data);

        // è®¾ç½®kernelå®Œæˆå›è°ƒ

        // é˜¶æ®µ3: å¯åŠ¨å†…å­˜æ‹·è´+æ³¨å†Œå›è°ƒï¼ˆå¼‚æ­¥ï¼‰â†’ ç«‹å³è¿”å›(è¿™ä¸ªç«‹å³è¿”å›åŸ‹ä¸‹äº†ä¼ç¬”)
        // start_memory_copy_stage(*async_data);
        // ğŸ”¥ ä¿®æ”¹çš„é˜¶æ®µ3: æŠŠå†…å­˜æ‹·è´ä»»åŠ¡æäº¤åˆ°çº¿ç¨‹æ± 
        submit_memory_copy_task(async_data, q);

#ifdef DEBUG
        printf("[DEBUG] âœ… Async pipeline launched successfully\n");
#endif

    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ Failed to launch async pipeline: %s\n", e.what());
#endif
        std::cerr << "Failed to launch async pipeline: " << e.what() << std::endl;
        delete async_data;
    }
}



// ğŸ”¥ æ–°å‡½æ•°ï¼šæäº¤å†…å­˜æ‹·è´ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
void submit_memory_copy_task(AsyncGpuPipeline::AsyncTaskData* data, PriorityQueue& q) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ“¤ submit_memory_copy_task: Submitting memory copy task to thread pool\n");
#endif

#ifdef DEBUG
            printf("[DEBUG] âœ… start launch async  copying results back\n");
#endif
    // ğŸ”¥ å…³é”®ï¼šä½¿ç”¨åŒä¸€ä¸ª compute_streamï¼Œè‡ªåŠ¨ç­‰å¾…kernelå®Œæˆ
    // è¿™é‡Œå¼‚æ­¥ä¸€ä¸‹ï¼Œ ç„¶å æäº¤çš„ä»»åŠ¡ä¹Ÿæ˜¯å¼‚æ­¥ï¼Œ ç„¶åæ¥æ”¶ä»»åŠ¡çš„ çº¿ç¨‹å°±éœ€è¦ç­‰å¾…äº†ã€‚
    cudaError_t err = cudaMemcpyAsync(data->gpu_buffer, data->d_guess_buffer,
                                     data->result_len * sizeof(char),
                                     cudaMemcpyDeviceToHost, data->compute_stream);
    if (err != cudaSuccess) {
        std::cerr << "Memory copy scheduling failed: " << cudaGetErrorString(err) << std::endl;

        return;
    }

#ifdef DEBUG
            printf("[DEBUG] âœ… launch async  copying results back succesfully\n");
#endif
    // ğŸ”¥ å…³é”®ï¼šæäº¤åˆ°çº¿ç¨‹æ± ï¼Œå—åˆ°MAX_PENDING_TASKSé™åˆ¶
    thread_pool->enqueue([data, &q]() {
        try {
#ifdef DEBUG
            printf("[DEBUG] ğŸ§µ Memory copy task started - waiting for GPU...\n");
#endif
            
            // ğŸ”¥ ç­‰å¾…GPU kernelå®Œæˆï¼ˆåŒæ­¥ç‚¹ï¼‰
            cudaError_t sync_err = cudaStreamSynchronize(data->compute_stream);
            if (sync_err != cudaSuccess) {
                throw std::runtime_error("GPU kernel execution failed: " + std::string(cudaGetErrorString(sync_err)));
            }

#ifdef DEBUG
            printf("[DEBUG] âœ… Memory copy completed, processing results\n");
#endif
            

            
            // CPUå¤„ç†é˜¶æ®µ
            process_strings_stage(*data);
            
            // åˆå¹¶ç»“æœ
            merge_results_stage(*data);
            
            // æ¸…ç†èµ„æº
            synchronous_cleanup(*data);

#ifdef DEBUG
            printf("[DEBUG] âœ… Memory copy task completed successfully\n");
#endif

        } catch (const std::exception& e) {
            std::cerr << "Memory copy task failed: " << e.what() << std::endl;
            data->has_error = true;
            
            // é”™è¯¯æ—¶ä¹Ÿè¦æ¸…ç†
            try {
                synchronous_cleanup(*data);
            } catch (...) {
                std::cerr << "Cleanup also failed during error handling" << std::endl;
            }
        }
        
        // ğŸ”¥ åœ¨ä»»åŠ¡çœŸæ­£å®Œæˆåé€’å‡è®¡æ•°å™¨
#ifdef TASK_COUNT
        int cur_task = --pending_task_count;
        cout << "now -1 has  " << cur_task << " tasks (memory copy completed)\n";
#endif
    });
#ifdef TASK_COUNT
        int cur_task = ++pending_task_count;
        cout << "now -1 has  " << cur_task << " tasks (memory copy completed)\n";
#endif
#ifdef DEBUG
    printf("[DEBUG] ğŸ“¤ Memory copy task submitted to thread pool\n");
#endif
}

// å‡†å¤‡GPUæ•°æ®é˜¶æ®µ (åŒæ­¥, é™¤å¼€ å†…å­˜å¤åˆ¶)
void prepare_gpu_data_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ prepare_gpu_data_stage: Starting data preparation...\n");
#endif

    TaskManager& tm = data.task_manager;

    //1. å‡†å¤‡æ•°æ®ï¼ˆç±»ä¼¼åŸæ¥çš„é€»è¾‘ï¼‰
    Taskcontent h_tasks;

    data.result_len = 0;

    h_tasks.seg_types = tm.seg_types.data();
    h_tasks.seg_ids = tm.seg_ids.data();

    // âš ï¸ ä¿®å¤ï¼šä¿å­˜å­—ç¬¦ä¸²åˆ°dataä¸­
    data.all_prefixes = std::accumulate(tm.prefixs.begin(), tm.prefixs.end(), std::string(""));
    h_tasks.prefixs = data.all_prefixes.c_str();

#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ Data preparation: taskcount=%d, guesscount=%d, prefixes_len=%zu\n",
           tm.taskcount, tm.guesscount, data.all_prefixes.length());
#endif

    data.h_prefix_offsets = new int[tm.prefixs.size() + 1];
    h_tasks.prefix_offsets = data.h_prefix_offsets;
    h_tasks.prefix_offsets[0] = 0;

    for (size_t i = 0; i < tm.prefixs.size(); ++i) {
        h_tasks.prefix_offsets[i + 1] = h_tasks.prefix_offsets[i] + tm.prefix_lens[i];
    }

    h_tasks.prefix_lens = tm.prefix_lens.data();
    h_tasks.taskcount = tm.taskcount;
    h_tasks.guesscount = tm.guesscount;
    h_tasks.seg_lens = tm.seg_lens.data();
    h_tasks.seg_value_counts = tm.seg_value_count.data();


    // âš ï¸ ä¿®å¤ï¼šä¿å­˜åç§»é‡åˆ°dataä¸­
    data.res_offset.clear();  // æ¸…ç©ºè€Œä¸æ˜¯resize
    data.cumulative_offsets.resize(tm.taskcount + 1, 0);

    // è®¡ç®—åç§»é‡
    for(int i = 0; i < tm.taskcount; i++){
        data.res_offset.push_back(data.result_len);  // è¿™æ ·å°±æ­£ç¡®äº†
        data.result_len += tm.seg_value_count[i] * (tm.seg_lens[i] + tm.prefix_lens[i]);
        data.cumulative_offsets[i + 1] = data.cumulative_offsets[i] + tm.seg_value_count[i];
    }
    h_tasks.output_offsets = data.res_offset.data();
    h_tasks.cumulative_guess_offsets = data.cumulative_offsets.data();

    // åˆ†é…host buffer
    data.gpu_buffer = new char[data.result_len];

    //2. åˆ†é…GPUå†…å­˜
    CUDA_CHECK(cudaMalloc(&data.temp_prefixs, h_tasks.prefix_offsets[tm.prefixs.size()] * sizeof(char)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_types, tm.taskcount * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_ids, tm.taskcount * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_lens, tm.seg_lens.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_prefix_offsets, (tm.prefixs.size() + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_prefix_lens, tm.prefix_lens.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_value_counts, tm.seg_value_count.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_cumulative_guess_offsets, (tm.taskcount + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_output_offsets, (tm.taskcount + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_tasks, sizeof(Taskcontent)));
    CUDA_CHECK(cudaMalloc(&data.d_guess_buffer, data.result_len * sizeof(char)));


    
    //3. ğŸ”¥ åŒæ­¥æ‹·è´æ•°æ®åˆ°GPU
    CUDA_CHECK(cudaMemcpy(data.d_seg_types, h_tasks.seg_types, tm.taskcount * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_seg_ids, h_tasks.seg_ids, tm.taskcount * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_seg_lens, h_tasks.seg_lens, tm.seg_lens.size() * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.temp_prefixs, h_tasks.prefixs, h_tasks.prefix_offsets[tm.prefixs.size()] * sizeof(char),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_prefix_offsets, h_tasks.prefix_offsets, (tm.prefixs.size() + 1) * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_prefix_lens, h_tasks.prefix_lens, tm.prefixs.size() * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_seg_value_counts, h_tasks.seg_value_counts, tm.seg_value_count.size() * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_cumulative_guess_offsets, h_tasks.cumulative_guess_offsets, (tm.taskcount + 1) * sizeof(int),
                          cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(data.d_output_offsets, h_tasks.output_offsets, (tm.taskcount + 1) * sizeof(int),
                          cudaMemcpyHostToDevice));



    // å‡†å¤‡Taskcontentç»“æ„
    data.task_content.seg_types = data.d_seg_types;
    data.task_content.seg_ids = data.d_seg_ids;
    data.task_content.seg_lens = data.d_seg_lens;
    data.task_content.prefixs = data.temp_prefixs;
    data.task_content.prefix_offsets = data.d_prefix_offsets;
    data.task_content.prefix_lens = data.d_prefix_lens;
    data.task_content.seg_value_counts = data.d_seg_value_counts;
    data.task_content.cumulative_guess_offsets = data.d_cumulative_guess_offsets;
    data.task_content.output_offsets = data.d_output_offsets;
    data.task_content.taskcount = tm.taskcount;
    data.task_content.guesscount = tm.guesscount;

    CUDA_CHECK(cudaMemcpy(data.d_tasks, &data.task_content, sizeof(Taskcontent),
                          cudaMemcpyHostToDevice));

#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ prepare_gpu_data_stage: Data preparation completed, result_len=%zu\n", data.result_len);
#endif
}

// å¯åŠ¨kernelé˜¶æ®µï¼ˆçº¯å¼‚æ­¥ï¼‰
void launch_kernel_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ”¥ launch_kernel_stage: Starting kernel launch...\n");
#endif

    // ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ‰€æœ‰å…³é”®å˜é‡æ˜¯å¦å­˜åœ¨
    printf("[DEBUG] ğŸ” Checking all variables before kernel launch:\n");

    // æ£€æŸ¥ gpu_dataï¼ˆå…¨å±€å˜é‡ï¼‰
    if (gpu_data == nullptr) {
        printf("[ERROR] âŒ gpu_data is NULL! This is likely the cause of 'invalid resource handle'\n");
        throw std::runtime_error("gpu_data is not initialized");
    } else {
        printf("[DEBUG] yes gpu_data is valid: %p\n", gpu_data);
    }

    // æ£€æŸ¥ data çš„å…³é”®GPUæŒ‡é’ˆ
    printf("[DEBUG] ğŸ” Checking AsyncTaskData GPU pointers:\n");
    
    if (data.d_tasks == nullptr) {
        printf("[ERROR] âŒ data.d_tasks is NULL!\n");
        throw std::runtime_error("d_tasks is not allocated");
    } else {
        printf("[DEBUG] yes data.d_tasks is valid: %p\n", data.d_tasks);
    }

    if (data.d_guess_buffer == nullptr) {
        printf("[ERROR] âŒ data.d_guess_buffer is NULL!\n");
        throw std::runtime_error("d_guess_buffer is not allocated");
    } else {
        printf("[DEBUG] yes data.d_guess_buffer is valid: %p\n", data.d_guess_buffer);
    }

    if (data.compute_stream == nullptr) {
        printf("[ERROR] âŒ data.compute_stream is NULL!\n");
        throw std::runtime_error("compute_stream is not created");
    } else {
        printf("[DEBUG] yes data.compute_stream is valid: %p\n", data.compute_stream);
    }

    // æ£€æŸ¥å…¶ä»–å…³é”®GPUæŒ‡é’ˆ
    printf("[DEBUG] ğŸ” Checking other GPU memory allocations:\n");
    printf("[DEBUG] - temp_prefixs: %p %s\n", data.temp_prefixs, data.temp_prefixs ? "yes" : "no");
    printf("[DEBUG] - d_seg_types: %p %s\n", data.d_seg_types, data.d_seg_types ? "yes" : "no");
    printf("[DEBUG] - d_seg_ids: %p %s\n", data.d_seg_ids, data.d_seg_ids ? "yes" : "no");
    printf("[DEBUG] - d_seg_lens: %p %s\n", data.d_seg_lens, data.d_seg_lens ? "yes" : "no");
    printf("[DEBUG] - d_prefix_offsets: %p %s\n", data.d_prefix_offsets, data.d_prefix_offsets ? "yes" : "no");
    printf("[DEBUG] - d_prefix_lens: %p %s\n", data.d_prefix_lens, data.d_prefix_lens ? "yes" : "no");
    printf("[DEBUG] - d_seg_value_counts: %p %s\n", data.d_seg_value_counts, data.d_seg_value_counts ? "yes" : "no");
    printf("[DEBUG] - d_cumulative_guess_offsets: %p %s\n", data.d_cumulative_guess_offsets, data.d_cumulative_guess_offsets ? "yes" : "no");
    printf("[DEBUG] - d_output_offsets: %p %s\n", data.d_output_offsets, data.d_output_offsets ? "yes" : "no");

    // æ£€æŸ¥TaskManageræ•°æ®çš„æœ‰æ•ˆæ€§
    TaskManager& tm = data.task_manager;
    printf("[DEBUG] ğŸ” Checking TaskManager data:\n");
    printf("[DEBUG] - taskcount: %d\n", tm.taskcount);
    printf("[DEBUG] - guesscount: %d\n", tm.guesscount);
    printf("[DEBUG] - seg_ids.size(): %zu\n", tm.seg_ids.size());
    printf("[DEBUG] - seg_lens.size(): %zu\n", tm.seg_lens.size());
    printf("[DEBUG] - prefixs.size(): %zu\n", tm.prefixs.size());
    printf("[DEBUG] - result_len: %zu\n", data.result_len);

    // æ£€æŸ¥å†…æ ¸å¯åŠ¨å‚æ•°çš„åˆç†æ€§
    int total_threads_needed = (tm.guesscount + GUESS_PER_THREAD - 1) / GUESS_PER_THREAD;
    int threads_per_block = 1024;
    int blocks = (total_threads_needed + threads_per_block - 1) / threads_per_block;

    printf("[DEBUG] ğŸ” Checking kernel launch parameters:\n");
    printf("[DEBUG] - GUESS_PER_THREAD: %d\n", GUESS_PER_THREAD);
    printf("[DEBUG] - total_threads_needed: %d\n", total_threads_needed);
    printf("[DEBUG] - threads_per_block: %d\n", threads_per_block);
    printf("[DEBUG] - blocks: %d\n", blocks);



    // å¼‚æ­¥å¯åŠ¨kernel
    generate_guesses_kernel<<<blocks, threads_per_block, 0, data.compute_stream>>>
        (gpu_data, data.d_tasks, data.d_guess_buffer);



    // æ£€æŸ¥å¯åŠ¨é”™è¯¯
    CUDA_CHECK(cudaGetLastError());

#ifdef DEBUG
    printf("[DEBUG] ğŸ”¥ launch_kernel_stage: Kernel launched successfully\n");
#endif
}




// å¤„ç†å­—ç¬¦ä¸²é˜¶æ®µ
void process_strings_stage(AsyncGpuPipeline::AsyncTaskData& data) {

#ifdef DEBUG
    printf("[DEBUG] ğŸ” process_strings_stage: Entry - thread_id=%zu\n", std::this_thread::get_id());
    fflush(stdout);
#endif
    TaskManager& tm = data.task_manager;

    // âš ï¸ æ£€æŸ¥é”™è¯¯çŠ¶æ€
    if (data.has_error) {
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ process_strings_stage: Skipping due to error state\n");
        fflush(stdout);
#endif
        return;
    }


#ifdef DEBUG
printf("[DEBUG] ğŸ” process_strings_stage: Processing %d segments, %d total guesses\n",
        (int)tm.seg_ids.size(), tm.guesscount);
printf("[DEBUG] ğŸ” Buffer info: gpu_buffer=%p, result_len=%zu\n",
        data.gpu_buffer, data.result_len);
fflush(stdout);
#endif

    data.local_guesses.reserve(tm.guesscount);

#ifdef DEBUG
        printf("[DEBUG] ğŸ” Reserved space for %d guesses\n", tm.guesscount);
        fflush(stdout);
#endif

    try {
        data.local_guesses.reserve(tm.guesscount);

#ifdef DEBUG
        printf("[DEBUG] ğŸ” Reserved space for %d guesses\n", tm.guesscount);
        fflush(stdout);
#endif

        for (int i = 0; i < tm.seg_ids.size(); i++) {
#ifdef DEBUG
            if (i < 3) {  // åªæ‰“å°å‰3ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                printf("[DEBUG] ğŸ” Processing segment %d: seg_value_count=%d, seg_len=%d, prefix_len=%d\n",
                       i, tm.seg_value_count[i], tm.seg_lens[i], tm.prefix_lens[i]);
                fflush(stdout);
            }
#endif

            for (int j = 0; j < tm.seg_value_count[i]; j++) {
                int start_offset = data.res_offset[i] + j * (tm.seg_lens[i] + tm.prefix_lens[i]);

#ifdef DEBUG
                if (i < 2 && j < 2) {  // åªæ‰“å°å‰å‡ ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                    printf("[DEBUG] ğŸ” Creating guess[%d][%d]: offset=%d, length=%d\n",
                           i, j, start_offset, tm.seg_lens[i] + tm.prefix_lens[i]);
                    fflush(stdout);
                }
#endif

                // æ£€æŸ¥è¾¹ç•Œ
                if (start_offset + tm.seg_lens[i] + tm.prefix_lens[i] > data.result_len) {
#ifdef DEBUG
                    printf("[DEBUG] âŒ Buffer overflow! offset=%d, length=%d, result_len=%zu\n",
                           start_offset, tm.seg_lens[i] + tm.prefix_lens[i], data.result_len);
                    fflush(stdout);
#endif
                    data.has_error = true;
                    return;
                }

                data.local_guesses.emplace_back(
                    data.gpu_buffer + start_offset,
                    tm.seg_lens[i] + tm.prefix_lens[i]
                );
            }
        }

#ifdef DEBUG
        printf("[DEBUG] âœ… process_strings_stage: Created %zu guesses successfully\n",
               data.local_guesses.size());
        fflush(stdout);
#endif

    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ process_strings_stage exception: %s\n", e.what());
        fflush(stdout);
#endif
        data.has_error = true;
    }

}

// åˆå¹¶ç»“æœé˜¶æ®µ
void merge_results_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ”— merge_results_stage: Entry - thread_id=%zu\n", std::this_thread::get_id());
    fflush(stdout);
#endif
    // âš ï¸ æ£€æŸ¥é”™è¯¯çŠ¶æ€
    if (data.has_error) {
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ merge_results_stage: Skipping due to error state\n");
        fflush(stdout);
#endif
        return;
    }


#ifdef DEBUG
    printf("[DEBUG] ğŸ”— merge_results_stage: Merging %zu guesses\n", data.local_guesses.size());
    fflush(stdout);
#endif


    try {
#ifdef DEBUG
        printf("[DEBUG] ğŸ”— Attempting to acquire locks...\n");
        fflush(stdout);
#endif

        {
            // std::lock_guard<std::mutex> lock1(main_data_mutex);

#ifdef DEBUG
            printf("[DEBUG] ğŸ”— main_data_mutex acquired\n");
            fflush(stdout);
#endif

            // std::lock_guard<std::mutex> lock2(gpu_buffer_mutex);
            std::scoped_lock lock(main_data_mutex, gpu_buffer_mutex);

#ifdef DEBUG
            printf("[DEBUG] ğŸ”— gpu_buffer_mutex acquired\n");
            printf("[DEBUG] ğŸ”— Current queue size: %zu\n", q.guesses.size());
            fflush(stdout);
#endif

            // æ’å…¥çŒœæµ‹ç»“æœåˆ°ä¸»é˜Ÿåˆ—
            q.guesses.insert(q.guesses.end(),
                             data.local_guesses.begin(),
                             data.local_guesses.end());

#ifdef DEBUG
            printf("[DEBUG] ğŸ”— Guesses inserted, new queue size: %zu\n", q.guesses.size());
            fflush(stdout);
#endif

            // å°†GPUç¼“å†²åŒºæŒ‡é’ˆåŠ å…¥ç®¡ç†åˆ—è¡¨
            if (data.gpu_buffer != nullptr) {
                pending_gpu_buffers.push_back(data.gpu_buffer);
                data.gpu_buffer = nullptr;
#ifdef DEBUG
                printf("[DEBUG] ğŸ”— GPU buffer added to pending list, total pending: %zu\n",
                       pending_gpu_buffers.size());
                fflush(stdout);
#endif
            } else {
                cout << " gpu_buffer ptr WRONG in merge_stage" << endl;
            }

#ifdef DEBUG
            printf("[DEBUG] ğŸ”— Releasing locks...\n");
            fflush(stdout);
#endif
        }

#ifdef DEBUG
        printf("[DEBUG] âœ… merge_results_stage: Completed successfully\n");
        fflush(stdout);
#endif

    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ merge_results_stage exception: %s\n", e.what());
        fflush(stdout);
#endif
        data.has_error = true;
    }
}


// æ™ºèƒ½æ¸…ç†é˜¶æ®µï¼ˆæ­£å¸¸æ—¶å¼‚æ­¥ï¼Œå¼‚å¸¸æ—¶åŒæ­¥ï¼‰
void cleanup_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ§¹ cleanup_stage: Starting resource cleanup (error=%s)...\n",
           data.has_error ? "true" : "false");
#endif

    if (data.has_error) {
        // ğŸš¨ å¼‚å¸¸æƒ…å†µï¼šæ‡’å¾—æ¸…ç†äº†ã€‚
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ Error detected in cleanup stage\n");
#endif
    } else {
        // âœ… æ­£å¸¸æƒ…å†µï¼šå¼‚æ­¥æ¸…ç†ï¼Œæé«˜æ€§èƒ½
#ifdef DEBUG
        printf("[DEBUG] âœ… Normal completion, performing asynchronous cleanup\n");
#endif
        synchronous_cleanup(data);
#ifdef DEBUG
        printf("[DEBUG] âœ… Normal completion,  asynchronous cleanup submitted\n");
#endif
    }
}


// åŒæ­¥æ­¥æ¸…ç†ï¼ˆç”¨äºæ­£å¸¸æƒ…å†µï¼‰
void synchronous_cleanup(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] âš¡ synchronous_cleanup: Scheduling async GPU memory release...\n");
#endif

    // ğŸ”¥ ä½¿ç”¨å¼‚æ­¥é‡Šæ”¾ï¼Œä¸é˜»å¡å½“å‰çº¿ç¨‹
    // if (data.temp_prefixs) cudaFreeAsync(data.temp_prefixs, data.compute_stream);
    // if (data.d_seg_types) cudaFreeAsync(data.d_seg_types, data.compute_stream);
    // if (data.d_seg_ids) cudaFreeAsync(data.d_seg_ids, data.compute_stream);
    // if (data.d_seg_lens) cudaFreeAsync(data.d_seg_lens, data.compute_stream);
    // if (data.d_prefix_offsets) cudaFreeAsync(data.d_prefix_offsets, data.compute_stream);
    // if (data.d_prefix_lens) cudaFreeAsync(data.d_prefix_lens, data.compute_stream);
    // if (data.d_seg_value_counts) cudaFreeAsync(data.d_seg_value_counts, data.compute_stream);
    // if (data.d_cumulative_guess_offsets) cudaFreeAsync(data.d_cumulative_guess_offsets, data.compute_stream);
    // if (data.d_output_offsets) cudaFreeAsync(data.d_output_offsets, data.compute_stream);
    // if (data.d_tasks) cudaFreeAsync(data.d_tasks, data.compute_stream);
    // if (data.d_guess_buffer) cudaFreeAsync(data.d_guess_buffer, data.compute_stream);
    // ğŸ”¥ åŒæ­¥é‡Šæ”¾GPUå†…å­˜
    cudaError_t sync_err = cudaStreamSynchronize(data.compute_stream);
    if (sync_err != cudaSuccess) {
        std::cerr << "Stream synchronization failed: " << cudaGetErrorString(sync_err) << std::endl;
    }
#ifdef DEBUG
    printf("[DEBUG] âš¡ Stream synchronized, GPU operations completed\n");
#endif
    if (data.temp_prefixs)  cudaFree(data.temp_prefixs);
    if (data.d_seg_types) cudaFree(data.d_seg_types);
    if (data.d_seg_ids) cudaFree(data.d_seg_ids);
    if (data.d_seg_lens) cudaFree(data.d_seg_lens);
    if (data.d_prefix_offsets) cudaFree(data.d_prefix_offsets);
    if (data.d_prefix_lens) cudaFree(data.d_prefix_lens);
    if (data.d_seg_value_counts) cudaFree(data.d_seg_value_counts);
    if (data.d_cumulative_guess_offsets) cudaFree(data.d_cumulative_guess_offsets);
    if (data.d_output_offsets) cudaFree(data.d_output_offsets);
    if (data.d_tasks) cudaFree(data.d_tasks);
    if (data.d_guess_buffer) cudaFree(data.d_guess_buffer);
    data.temp_prefixs = nullptr;
    data.d_seg_types = nullptr;
    data.d_seg_ids = nullptr;
    data.d_seg_lens = nullptr;
    data.d_prefix_offsets = nullptr;
    data.d_prefix_lens = nullptr;
    data.d_seg_value_counts = nullptr;
    data.d_cumulative_guess_offsets = nullptr;
    data.d_output_offsets = nullptr;
    data.d_tasks = nullptr;
    data.d_guess_buffer = nullptr;

    if (data.h_prefix_offsets) {
        delete[] data.h_prefix_offsets;
        data.h_prefix_offsets = nullptr;
    }
#ifdef DEBUG
    printf("[DEBUG] âœ… synchronous_cleanup: All resources cleaned\n");
#endif

#ifdef DEBUG
    cout << "begin delete asynctaskdata" << endl;
#endif
    //æ”¹æˆåŒæ­¥
    delete &data;


#ifdef DEBUG
    cout << "end delete asynctaskdata " << endl;

    if (data.gpu_buffer != nullptr) {
        cout << "Error, gpu_buffer ptr should be nullptr in async_cleanup" << endl;
    }
#endif


}



