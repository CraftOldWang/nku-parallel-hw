#include "guessing_cuda.h"
#include "PCFG.h"


#define CUDA_CHECK(call) \
    do { \
        cudaError_t err__ = (call); \
        if (err__ != cudaSuccess) { \
            fprintf(stderr, "\033[1;31m[CUDA ERROR]\033[0m %s:%d: %s (%d)\n", \
                __FILE__, __LINE__, cudaGetErrorString(err__), err__); \
            exit(EXIT_FAILURE); \
        } \
    } while (0)

// å®‰å…¨çš„CUDAé”™è¯¯æ£€æŸ¥ï¼ˆç”¨äºå›è°ƒå‡½æ•°ï¼‰
#define CUDA_CHECK_CALLBACK(call, cleanup_action) \
    do { \
        cudaError_t err__ = (call); \
        if (err__ != cudaSuccess) { \
            std::cerr << "CUDA error in callback: " << cudaGetErrorString(err__) << std::endl; \
            cleanup_action; \
            return; \
        } \
    } while (0)

AsyncGpuPipeline::AsyncTaskData::AsyncTaskData(TaskManager&& tm)
    : task_manager(std::move(tm)), gpu_buffer(nullptr) {
    // åˆ›å»ºCUDA streamså’Œevents
    cudaStreamCreate(&compute_stream);

    // åˆå§‹åŒ–æŒ‡é’ˆ
    temp_prefixs = nullptr;
    d_seg_types = nullptr;
    d_seg_ids = nullptr;
    d_seg_lens = nullptr;
    d_prefix_offsets = nullptr;
    d_prefix_lens = nullptr;
    d_seg_value_counts = nullptr;
    d_cumulative_guess_offsets = nullptr;
    d_output_offsets = nullptr;
    d_tasks = nullptr;
    d_guess_buffer = nullptr;
    h_prefix_offsets = nullptr;
    result_len = 0;
}

AsyncGpuPipeline::AsyncTaskData::~AsyncTaskData(){
            // æ¸…ç†CUDAèµ„æº
            if (compute_stream) cudaStreamDestroy(compute_stream);
}





void AsyncGpuPipeline::launch_async_pipeline(TaskManager tm, PriorityQueue& q) {
    
    auto* async_data = new AsyncTaskData(std::move(tm));
    
    try {
        // é˜¶æ®µ1: å‡†å¤‡æ•°æ®ï¼ˆåŒæ­¥ï¼Œä½†å¯ä»¥ä¼˜åŒ–ï¼‰
        prepare_gpu_data_stage(*async_data);
        
        // é˜¶æ®µ2: å¼‚æ­¥å¯åŠ¨GPU kernel
        launch_kernel_stage(*async_data);
        
        // è®¾ç½®kernelå®Œæˆå›è°ƒ
   
        // é˜¶æ®µ3: å¯åŠ¨å†…å­˜æ‹·è´+æ³¨å†Œå›è°ƒï¼ˆå¼‚æ­¥ï¼‰â†’ ç«‹å³è¿”å›
        start_memory_copy_stage(*async_data);

#ifdef DEBUG
        printf("[DEBUG] âœ… Async pipeline launched successfully\n");
#endif
                             
    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ Failed to launch async pipeline: %s\n", e.what());
#endif
        std::cerr << "Failed to launch async pipeline: " << e.what() << std::endl;
        delete async_data;
    }
}

// å‡†å¤‡GPUæ•°æ®é˜¶æ®µ (åŒæ­¥, é™¤å¼€ å†…å­˜å¤åˆ¶)
void prepare_gpu_data_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ prepare_gpu_data_stage: Starting data preparation...\n");
#endif
    
    TaskManager& tm = data.task_manager;
    
    //1. å‡†å¤‡æ•°æ®ï¼ˆç±»ä¼¼åŸæ¥çš„é€»è¾‘ï¼‰
    Taskcontent h_tasks; 
    Taskcontent temp;
    
    data.result_len = 0;
    
    h_tasks.seg_types = tm.seg_types.data();
    h_tasks.seg_ids = tm.seg_ids.data();

    // âš ï¸ ä¿®å¤ï¼šä¿å­˜å­—ç¬¦ä¸²åˆ°dataä¸­
    data.all_prefixes = std::accumulate(tm.prefixs.begin(), tm.prefixs.end(), std::string(""));
    h_tasks.prefixs = data.all_prefixes.c_str();
    
#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ Data preparation: taskcount=%d, guesscount=%d, prefixes_len=%zu\n", 
           tm.taskcount, tm.guesscount, data.all_prefixes.length());
#endif
    
    data.h_prefix_offsets = new int[tm.prefixs.size() + 1];
    h_tasks.prefix_offsets = data.h_prefix_offsets;
    h_tasks.prefix_offsets[0] = 0;
    
    for (size_t i = 0; i < tm.prefixs.size(); ++i) {
        h_tasks.prefix_offsets[i + 1] = h_tasks.prefix_offsets[i] + tm.prefix_lens[i];
    }
    
    h_tasks.prefix_lens = tm.prefix_lens.data();
    h_tasks.taskcount = tm.taskcount;
    h_tasks.guesscount = tm.guesscount;
    h_tasks.seg_lens = tm.seg_lens.data();
    h_tasks.seg_value_counts = tm.seg_value_count.data();
   
   
    // âš ï¸ ä¿®å¤ï¼šä¿å­˜åç§»é‡åˆ°dataä¸­
    data.res_offset.clear();  // æ¸…ç©ºè€Œä¸æ˜¯resize
    data.cumulative_offsets.resize(tm.taskcount + 1, 0);

    // è®¡ç®—åç§»é‡
    for(int i = 0; i < tm.taskcount; i++){
        data.res_offset.push_back(data.result_len);  // è¿™æ ·å°±æ­£ç¡®äº†
        data.result_len += tm.seg_value_count[i] * (tm.seg_lens[i] + tm.prefix_lens[i]);
        data.cumulative_offsets[i + 1] = data.cumulative_offsets[i] + tm.seg_value_count[i];
    }
    h_tasks.output_offsets = data.res_offset.data();
    h_tasks.cumulative_guess_offsets = data.cumulative_offsets.data();
    
    // åˆ†é…host buffer
    data.gpu_buffer = new char[data.result_len];
    
    //2. åˆ†é…GPUå†…å­˜
    CUDA_CHECK(cudaMalloc(&data.temp_prefixs, h_tasks.prefix_offsets[tm.prefixs.size()] * sizeof(char)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_types, tm.taskcount * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_ids, tm.taskcount * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_lens, tm.seg_lens.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_prefix_offsets, (tm.prefixs.size() + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_prefix_lens, tm.prefix_lens.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_seg_value_counts, tm.seg_value_count.size() * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_cumulative_guess_offsets, (tm.taskcount + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_output_offsets, (tm.taskcount + 1) * sizeof(int)));
    CUDA_CHECK(cudaMalloc(&data.d_tasks, sizeof(Taskcontent)));
    CUDA_CHECK(cudaMalloc(&data.d_guess_buffer, data.result_len * sizeof(char)));
    
    //3. å¼‚æ­¥æ‹·è´æ•°æ®åˆ°GPU
    CUDA_CHECK(cudaMemcpyAsync(data.d_seg_types, h_tasks.seg_types, tm.taskcount * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_seg_ids, h_tasks.seg_ids, tm.taskcount * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_seg_lens, h_tasks.seg_lens, tm.seg_lens.size() * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.temp_prefixs, h_tasks.prefixs, h_tasks.prefix_offsets[tm.prefixs.size()] * sizeof(char), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_prefix_offsets, h_tasks.prefix_offsets, (tm.prefixs.size() + 1) * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_prefix_lens, h_tasks.prefix_lens, tm.prefixs.size() * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_seg_value_counts, h_tasks.seg_value_counts, tm.seg_value_count.size() * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_cumulative_guess_offsets, h_tasks.cumulative_guess_offsets, (tm.taskcount + 1) * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    CUDA_CHECK(cudaMemcpyAsync(data.d_output_offsets, h_tasks.output_offsets, (tm.taskcount + 1) * sizeof(int), 
                              cudaMemcpyHostToDevice, data.compute_stream));
    
    // å‡†å¤‡Taskcontentç»“æ„
    temp.seg_types = data.d_seg_types;
    temp.seg_ids = data.d_seg_ids;
    temp.seg_lens = data.d_seg_lens;
    temp.prefixs = data.temp_prefixs;
    temp.prefix_offsets = data.d_prefix_offsets;
    temp.prefix_lens = data.d_prefix_lens;
    temp.seg_value_counts = data.d_seg_value_counts;
    temp.cumulative_guess_offsets = data.d_cumulative_guess_offsets;
    temp.output_offsets = data.d_output_offsets;
    temp.taskcount = tm.taskcount;
    temp.guesscount = tm.guesscount;
    
    CUDA_CHECK(cudaMemcpyAsync(data.d_tasks, &temp, sizeof(Taskcontent), 
                              cudaMemcpyHostToDevice, data.compute_stream));
#ifdef DEBUG
    printf("[DEBUG] ğŸ“‹ prepare_gpu_data_stage: Data preparation completed, result_len=%zu\n", data.result_len);
#endif
}

// å¯åŠ¨kernelé˜¶æ®µï¼ˆçº¯å¼‚æ­¥ï¼‰
void launch_kernel_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ”¥ launch_kernel_stage: Starting kernel launch...\n");
#endif    
    TaskManager& tm = data.task_manager;
    
    int total_threads_needed = (tm.guesscount + GUESS_PER_THREAD - 1) / GUESS_PER_THREAD;
    int threads_per_block = 1024;
    int blocks = (total_threads_needed + threads_per_block - 1) / threads_per_block;

#ifdef DEBUG
    printf("[DEBUG] ğŸ”¥ Kernel config: guesscount=%d, blocks=%d, threads_per_block=%d\n", 
           tm.guesscount, blocks, threads_per_block);
#endif
    
    // å¼‚æ­¥å¯åŠ¨kernel
    generate_guesses_kernel<<<blocks, threads_per_block, 0, data.compute_stream>>>
        (gpu_data, data.d_tasks, data.d_guess_buffer);
        

    
    // æ£€æŸ¥å¯åŠ¨é”™è¯¯
    CUDA_CHECK(cudaGetLastError());

#ifdef DEBUG
    printf("[DEBUG] ğŸ”¥ launch_kernel_stage: Kernel launched successfully\n");
#endif
}


// å¯åŠ¨å†…å­˜æ‹·è´é˜¶æ®µï¼ˆå®Œå…¨å¼‚æ­¥ï¼‰
void start_memory_copy_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ“¥ start_memory_copy_stage: Scheduling async memory copy...\n");
#endif

    // ğŸ”¥ å…³é”®ï¼šä½¿ç”¨åŒä¸€ä¸ª compute_streamï¼Œè‡ªåŠ¨ç­‰å¾…kernelå®Œæˆ
    cudaError_t err = cudaMemcpyAsync(data.gpu_buffer, data.d_guess_buffer, 
                                     data.result_len * sizeof(char), 
                                     cudaMemcpyDeviceToHost, data.compute_stream);
    if (err != cudaSuccess) {
        std::cerr << "Memory copy scheduling failed: " << cudaGetErrorString(err) << std::endl;

        return;
    }

    // ğŸ”¥ å…³é”®ï¼šæ³¨å†Œå†…å­˜æ‹·è´å®Œæˆå›è°ƒ
    err = cudaStreamAddCallback(data.compute_stream, 
                               AsyncGpuPipeline::memory_copy_completion_callback, 
                               &data, 0);
    if (err != cudaSuccess) {
        std::cerr << "Callback registration failed: " << cudaGetErrorString(err) << std::endl;
        return;
    }

#ifdef DEBUG
    printf("[DEBUG] ğŸ“¥ Memory copy scheduled with callback, stage 3 returning immediately\n");
#endif

    // ğŸ”¥ å…³é”®ï¼šç«‹å³è¿”å›ï¼åç»­å¤„ç†åœ¨å›è°ƒä¸­å®Œæˆ
}



// å†…å­˜æ‹·è´å®Œæˆå›è°ƒ - æ‰“åŒ…ä»»åŠ¡ç»™çº¿ç¨‹æ± 
void CUDART_CB AsyncGpuPipeline::memory_copy_completion_callback(cudaStream_t stream, cudaError_t status, void* userData) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ“¥ memory_copy_completion_callback: Entry - userData=%p, status=%d\n", 
           userData, status);
    fflush(stdout);
#endif

    if (!userData) {
#ifdef DEBUG
        printf("[DEBUG] âŒ userData is null in callback!\n");
        fflush(stdout);
#endif
        return;
    }

    auto* data = static_cast<AsyncGpuPipeline::AsyncTaskData*>(userData);
    

    //BUG æ¸…ç†å‡½æ•°æ„Ÿè§‰ä¸å¤ªå¯¹
    if (status != cudaSuccess) {
        std::cerr << "Memory copy failed: " << cudaGetErrorString(status) << std::endl;
        data->has_error = true;
        // é”™è¯¯å°±åˆ«ç®¡äº†ã€‚

        return;
    }

#ifdef DEBUG
    printf("[DEBUG] âœ… Memory copy successful, submitting CPU processing task to thread pool\n");
#endif

    // ğŸ”¥ å…³é”®ï¼šæ‰“åŒ…CPUå¤„ç†ä»»åŠ¡ï¼Œæäº¤ç»™çº¿ç¨‹æ± 
    thread_pool->enqueue([data]() {
        try {
#ifdef DEBUG
            printf("[DEBUG] ğŸ§µ Thread pool task started - processing results\n");
#endif
            // CPUå¤„ç†é˜¶æ®µ
            process_strings_stage(*data);

#ifdef DEBUG
            printf("[DEBUG] âœ… process_strings_stage completed s\n");
            fflush(stdout);
#endif
            merge_results_stage(*data);
#ifdef DEBUG
            printf("[DEBUG] âœ… merge_results_stage completed inms\n");
            fflush(stdout);
#endif
            cleanup_stage(*data);
            
#ifdef DEBUG
            printf("[DEBUG] âœ… Thread pool task completed successfully\n");
#endif
            
        } catch (const std::exception& e) {
            std::cerr << "CPU processing failed: " << e.what() << std::endl;
            data->has_error = true;
            // é”™è¯¯å°±åˆ«ç®¡äº†ã€‚
            // cleanup_stage(*data);
        }
        pending_task_count--;
        int cur_task = pending_task_count.load();
        cout << "now -1 has  " << cur_task << " tasks\n";

    });
    pending_task_count++;
    int cur_task = pending_task_count.load();
    cout << "now +1 has  " << cur_task << " tasks\n";

#ifdef DEBUG
    printf("[DEBUG] ğŸ“¤ CPU processing task submitted, callback returning\n");
#endif
}


// å¤„ç†å­—ç¬¦ä¸²é˜¶æ®µ
void process_strings_stage(AsyncGpuPipeline::AsyncTaskData& data) {
   
#ifdef DEBUG
    printf("[DEBUG] ğŸ” process_strings_stage: Entry - thread_id=%zu\n", std::this_thread::get_id());
    fflush(stdout);
#endif
    TaskManager& tm = data.task_manager;
    
    // âš ï¸ æ£€æŸ¥é”™è¯¯çŠ¶æ€
    if (data.has_error) {
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ process_strings_stage: Skipping due to error state\n");
        fflush(stdout);
#endif
        return;
    }

    
#ifdef DEBUG
printf("[DEBUG] ğŸ” process_strings_stage: Processing %d segments, %d total guesses\n", 
        (int)tm.seg_ids.size(), tm.guesscount);
printf("[DEBUG] ğŸ” Buffer info: gpu_buffer=%p, result_len=%zu\n", 
        data.gpu_buffer, data.result_len);
fflush(stdout);
#endif
    
    data.local_guesses.reserve(tm.guesscount);

#ifdef DEBUG
        printf("[DEBUG] ğŸ” Reserved space for %d guesses\n", tm.guesscount);
        fflush(stdout);
#endif

    try {
        data.local_guesses.reserve(tm.guesscount);
        
#ifdef DEBUG
        printf("[DEBUG] ğŸ” Reserved space for %d guesses\n", tm.guesscount);
        fflush(stdout);
#endif
        
        for (int i = 0; i < tm.seg_ids.size(); i++) {
#ifdef DEBUG
            if (i < 3) {  // åªæ‰“å°å‰3ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                printf("[DEBUG] ğŸ” Processing segment %d: seg_value_count=%d, seg_len=%d, prefix_len=%d\n", 
                       i, tm.seg_value_count[i], tm.seg_lens[i], tm.prefix_lens[i]);
                fflush(stdout);
            }
#endif
            
            for (int j = 0; j < tm.seg_value_count[i]; j++) {
                int start_offset = data.res_offset[i] + j * (tm.seg_lens[i] + tm.prefix_lens[i]);
                
#ifdef DEBUG
                if (i < 2 && j < 2) {  // åªæ‰“å°å‰å‡ ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                    printf("[DEBUG] ğŸ” Creating guess[%d][%d]: offset=%d, length=%d\n", 
                           i, j, start_offset, tm.seg_lens[i] + tm.prefix_lens[i]);
                    fflush(stdout);
                }
#endif
                
                // æ£€æŸ¥è¾¹ç•Œ
                if (start_offset + tm.seg_lens[i] + tm.prefix_lens[i] > data.result_len) {
#ifdef DEBUG
                    printf("[DEBUG] âŒ Buffer overflow! offset=%d, length=%d, result_len=%zu\n", 
                           start_offset, tm.seg_lens[i] + tm.prefix_lens[i], data.result_len);
                    fflush(stdout);
#endif
                    data.has_error = true;
                    return;
                }
                
                data.local_guesses.emplace_back(
                    data.gpu_buffer + start_offset,
                    tm.seg_lens[i] + tm.prefix_lens[i]
                );
            }
        }
        
#ifdef DEBUG
        printf("[DEBUG] âœ… process_strings_stage: Created %zu guesses successfully\n", 
               data.local_guesses.size());
        fflush(stdout);
#endif
        
    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ process_strings_stage exception: %s\n", e.what());
        fflush(stdout);
#endif
        data.has_error = true;
    }

}

// åˆå¹¶ç»“æœé˜¶æ®µ
void merge_results_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ”— merge_results_stage: Entry - thread_id=%zu\n", std::this_thread::get_id());
    fflush(stdout);
#endif
    // âš ï¸ æ£€æŸ¥é”™è¯¯çŠ¶æ€
    if (data.has_error) {
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ merge_results_stage: Skipping due to error state\n");
        fflush(stdout);
#endif
        return;
    }


#ifdef DEBUG
    printf("[DEBUG] ğŸ”— merge_results_stage: Merging %zu guesses\n", data.local_guesses.size());
    fflush(stdout);
#endif


    try {
#ifdef DEBUG
        printf("[DEBUG] ğŸ”— Attempting to acquire locks...\n");
        fflush(stdout);
#endif

        {
            std::lock_guard<std::mutex> lock1(main_data_mutex);
            
#ifdef DEBUG
            printf("[DEBUG] ğŸ”— main_data_mutex acquired\n");
            fflush(stdout);
#endif
            
            std::lock_guard<std::mutex> lock2(gpu_buffer_mutex);
            
#ifdef DEBUG
            printf("[DEBUG] ğŸ”— gpu_buffer_mutex acquired\n");
            printf("[DEBUG] ğŸ”— Current queue size: %zu\n", q.guesses.size());
            fflush(stdout);
#endif
            
            // æ’å…¥çŒœæµ‹ç»“æœåˆ°ä¸»é˜Ÿåˆ—
            q.guesses.insert(q.guesses.end(), 
                             data.local_guesses.begin(), 
                             data.local_guesses.end());

#ifdef DEBUG
            printf("[DEBUG] ğŸ”— Guesses inserted, new queue size: %zu\n", q.guesses.size());
            fflush(stdout);
#endif

            // å°†GPUç¼“å†²åŒºæŒ‡é’ˆåŠ å…¥ç®¡ç†åˆ—è¡¨
            if (data.gpu_buffer != nullptr) {
                pending_gpu_buffers.push_back(data.gpu_buffer);
                data.gpu_buffer = nullptr;
#ifdef DEBUG
                printf("[DEBUG] ğŸ”— GPU buffer added to pending list, total pending: %zu\n", 
                       pending_gpu_buffers.size());
                fflush(stdout);
#endif
            }
            
#ifdef DEBUG
            printf("[DEBUG] ğŸ”— Releasing locks...\n");
            fflush(stdout);
#endif
        }
        
#ifdef DEBUG
        printf("[DEBUG] âœ… merge_results_stage: Completed successfully\n");
        fflush(stdout);
#endif
        
    } catch (const std::exception& e) {
#ifdef DEBUG
        printf("[DEBUG] âŒ merge_results_stage exception: %s\n", e.what());
        fflush(stdout);
#endif
        data.has_error = true;
    }
}


// æ™ºèƒ½æ¸…ç†é˜¶æ®µï¼ˆæ­£å¸¸æ—¶å¼‚æ­¥ï¼Œå¼‚å¸¸æ—¶åŒæ­¥ï¼‰
void cleanup_stage(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ§¹ cleanup_stage: Starting resource cleanup (error=%s)...\n", 
           data.has_error ? "true" : "false");
#endif

    if (data.has_error) {
        // ğŸš¨ å¼‚å¸¸æƒ…å†µï¼šæ‡’å¾—æ¸…ç†äº†ã€‚
#ifdef DEBUG
        printf("[DEBUG] âš ï¸ Error detected in cleanup stage\n");
#endif
    } else {
        // âœ… æ­£å¸¸æƒ…å†µï¼šå¼‚æ­¥æ¸…ç†ï¼Œæé«˜æ€§èƒ½
#ifdef DEBUG
        printf("[DEBUG] âœ… Normal completion, performing asynchronous cleanup\n");
#endif
        asynchronous_cleanup(data);
#ifdef DEBUG
        printf("[DEBUG] âœ… Normal completion,  asynchronous cleanup submitted\n");
#endif
    }
}


// å¼‚æ­¥æ¸…ç†ï¼ˆç”¨äºæ­£å¸¸æƒ…å†µï¼‰
void asynchronous_cleanup(AsyncGpuPipeline::AsyncTaskData& data) {
#ifdef DEBUG
    printf("[DEBUG] âš¡ asynchronous_cleanup: Scheduling async GPU memory release...\n");
#endif

    // ğŸ”¥ ä½¿ç”¨å¼‚æ­¥é‡Šæ”¾ï¼Œä¸é˜»å¡å½“å‰çº¿ç¨‹
    if (data.temp_prefixs) cudaFreeAsync(data.temp_prefixs, data.compute_stream);
    if (data.d_seg_types) cudaFreeAsync(data.d_seg_types, data.compute_stream);
    if (data.d_seg_ids) cudaFreeAsync(data.d_seg_ids, data.compute_stream);
    if (data.d_seg_lens) cudaFreeAsync(data.d_seg_lens, data.compute_stream);
    if (data.d_prefix_offsets) cudaFreeAsync(data.d_prefix_offsets, data.compute_stream);
    if (data.d_prefix_lens) cudaFreeAsync(data.d_prefix_lens, data.compute_stream);
    if (data.d_seg_value_counts) cudaFreeAsync(data.d_seg_value_counts, data.compute_stream);
    if (data.d_cumulative_guess_offsets) cudaFreeAsync(data.d_cumulative_guess_offsets, data.compute_stream);
    if (data.d_output_offsets) cudaFreeAsync(data.d_output_offsets, data.compute_stream);
    if (data.d_tasks) cudaFreeAsync(data.d_tasks, data.compute_stream);
    if (data.d_guess_buffer) cudaFreeAsync(data.d_guess_buffer, data.compute_stream);


    // ğŸ”¥ å…³é”®ï¼šè®¾ç½®å¼‚æ­¥æ¸…ç†å®Œæˆå›è°ƒ
    cudaStreamAddCallback(data.compute_stream, 
                         AsyncGpuPipeline::async_cleanup_completion_callback, 
                         &data, 0);
    // é‡Šæ”¾CPUå†…å­˜
    if (data.h_prefix_offsets) {
        delete[] data.h_prefix_offsets;
        data.h_prefix_offsets = nullptr;
    }

#ifdef DEBUG
    if (data.gpu_buffer != nullptr) {
        cout << "Error, gpu_buffer ptr should be nullptr in async_cleanup" << endl;
    }
#endif
   
#ifdef DEBUG
    printf("[DEBUG] ğŸ“¥ Async cleanup scheduled with callback, returning immediately\n");
#endif
    
    // ğŸ”¥ ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…æ¸…ç†å®Œæˆ
}

// å¼‚æ­¥æ¸…ç†å®Œæˆå›è°ƒ
void CUDART_CB AsyncGpuPipeline::async_cleanup_completion_callback(cudaStream_t stream, cudaError_t status, void* userData) {
#ifdef DEBUG
    printf("[DEBUG] ğŸ§¹ async_cleanup_completion_callback: GPU memory released\n");
#endif

    auto* data = static_cast<AsyncGpuPipeline::AsyncTaskData*>(userData);
    
    if (status != cudaSuccess) {
        std::cerr << "Async cleanup failed: " << cudaGetErrorString(status) << std::endl;
        // åˆ«æ¸…ç†äº†ï¼Œ å‡å°‘é”™è¯¯ã€‚
        return;
    }

#ifdef DEBUG
    printf("[DEBUG] âœ… GPU memory cleanup successful, cleaning CPU memory\n");
#endif

#ifdef DEBUG
    printf("[DEBUG] ğŸ—‘ï¸ cleanup_cpu_memory: Releasing CPU memory...\n");
#endif

    // é‡Šæ”¾CPUå†…å­˜
    if (data->h_prefix_offsets) {
        delete[] data->h_prefix_offsets;
        data->h_prefix_offsets = nullptr;
    }
    
#ifdef DEBUG
    printf("[DEBUG] âœ… CPU memory cleanup completed\n");
#endif
    
    delete data;
    
#ifdef DEBUG
    printf("[DEBUG] âœ… AsyncTaskData deleted, pipeline fully completed\n");
#endif


}
